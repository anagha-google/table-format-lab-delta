{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4529a790-8425-4600-841a-4b094b82eaa8",
   "metadata": {},
   "source": [
    "# Delta Lake Lab \n",
    "## Unit 5: Schema Evolution\n",
    "\n",
    "In the previous unit, we -\n",
    "1. Did a delete operation on the base delta table and learned what happens to the underlying parquet and reviewed the transaction log\n",
    "2. Did an insert operation on the base delta table and learned what happens to the underlying parquet and reviewed the transaction log\n",
    "3. Did an update operation on the base delta table and learned what happens to the underlying parquet and reviewed the transaction log\n",
    "4. Did a merge (upsert) operation on the base delta table and learned what happens to the underlying parquet and reviewed the transaction log\n",
    "\n",
    "In this unit, we will -\n",
    "1. Study schema evolution possible with delta lake\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a31c4fd-d465-4f52-8e56-3775bf499abc",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1321bce9-178c-4065-8187-0a5728c1a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql.functions import month, date_format\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from delta.tables import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed295a74-ed1d-4b5d-831a-1b5dcf73c36f",
   "metadata": {},
   "source": [
    "### 2. Create a Spark session powered by Cloud Dataproc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b383d5ab-a0b9-45ab-a232-34d88f2a0065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/22 23:12:20 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://gdpic-srvls-session-cb959c82-1002-4915-aed8-85c83d4e81f4-m.us-central1-a.c.delta-lake-lab.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://gdpic-srvls-session-cb959c82-1002-4915-aed8-85c83d4e81f4-m:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f4d32628160>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Loan Analysis').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd13e6-f3f5-4f2c-b4fc-d7e2660c6206",
   "metadata": {},
   "source": [
    "### 3. Declare variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5596e31b-749a-4702-8879-6f05f9ff0c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID:  delta-lake-lab\n"
     ]
    }
   ],
   "source": [
    "project_id_output = !gcloud config list --format \"value(core.project)\" 2>/dev/null\n",
    "PROJECT_ID = project_id_output[0]\n",
    "print(\"PROJECT_ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "471c6743-a058-462b-851a-f34323f36243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_NAME:  delta-lake-lab\n"
     ]
    }
   ],
   "source": [
    "project_name_output = !gcloud projects describe $PROJECT_ID | grep name | cut -d':' -f2 | xargs\n",
    "PROJECT_NAME = project_name_output[0]\n",
    "print(\"PROJECT_NAME: \", PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61929dc6-a083-433c-8a13-3d39d9c4a4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_NUMBER:  885979867746\n"
     ]
    }
   ],
   "source": [
    "project_number_output = !gcloud projects describe $PROJECT_ID | grep projectNumber | cut -d':' -f2 | xargs\n",
    "PROJECT_NUMBER = project_number_output[0]\n",
    "print(\"PROJECT_NUMBER: \", PROJECT_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8b79fd2-5243-41a4-ae87-e7f9dd87cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LAKE_ROOT_PATH= f\"gs://dll-data-bucket-{PROJECT_NUMBER}\"\n",
    "DELTA_LAKE_DIR_ROOT = f\"{DATA_LAKE_ROOT_PATH}/delta-consumable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97b70135-a0e3-4f5b-a917-086775bc2d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://dll-data-bucket-885979867746/delta-consumable/:\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/part-00000-1ddad42e-603a-40c6-83b7-4ea3ae4a5128-c000.snappy.parquet\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/part-00000-407faca5-0109-4def-a655-a688e694cc6b-c000.snappy.parquet\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/part-00000-9566ead4-572a-4cc0-ba48-605bdfa18778-c000.snappy.parquet\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/part-00000-efb9177f-a191-4835-928a-0d7e4b72e8e0-c000.snappy.parquet\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/part-00000-f028020a-487f-4de7-9fb5-be01dd31b7af-c000.snappy.parquet\n",
      "\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/:\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000000.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000001.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000002.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000003.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000004.json\n",
      "\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_symlink_format_manifest/:\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_symlink_format_manifest/\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_symlink_format_manifest/manifest\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -r $DELTA_LAKE_DIR_ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed74d358-e90b-46d0-b81c-1e29c25ccac5",
   "metadata": {},
   "source": [
    "### 4. Existing schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bcc3cf8-6ecf-4efe-855d-b564401317bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/spark/conf/ivysettings.xml will be used\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                          |comment|\n",
      "+----------------------------+---------------------------------------------------+-------+\n",
      "|addr_state                  |string                                             |       |\n",
      "|count                       |bigint                                             |       |\n",
      "|                            |                                                   |       |\n",
      "|# Partitioning              |                                                   |       |\n",
      "|Not partitioned             |                                                   |       |\n",
      "|                            |                                                   |       |\n",
      "|# Detailed Table Information|                                                   |       |\n",
      "|Name                        |loan_db.loans_by_state_delta                       |       |\n",
      "|Location                    |gs://dll-data-bucket-885979867746/delta-consumable |       |\n",
      "|Provider                    |delta                                              |       |\n",
      "|Owner                       |spark                                              |       |\n",
      "|External                    |true                                               |       |\n",
      "|Table Properties            |[delta.minReaderVersion=1,delta.minWriterVersion=2]|       |\n",
      "+----------------------------+---------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE FORMATTED loan_db.loans_by_state_delta\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17581b81-035f-43b6-a4fa-48b55ce28c8c",
   "metadata": {},
   "source": [
    "### 5. Attempt to modify the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da4f7939-4668-4015-83eb-90209251ea03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|addr_state|count|    collateral_value|\n",
      "+----------+-----+--------------------+\n",
      "|        IA|   94|   948770.9115653402|\n",
      "|        CA| 9939| 9.939137216157739E7|\n",
      "|        IN| 3850|3.8502319893542394E7|\n",
      "+----------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add a column called collateral_value\n",
    "schemaEvolvedDF = sql(\"select addr_state, cast(rand(10)*count as bigint) as count, cast(rand(10) * 10000 * count as double) as collateral_value from loan_db.loans_by_state_delta\")\n",
    "schemaEvolvedDF.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e98a313e-98cf-43a6-b000-626c5f3672e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "A schema mismatch detected when writing to the Delta table (Table ID: 50aecee7-98f2-40ec-85ef-68af054ea14e).\nTo enable schema migration using DataFrameWriter or DataStreamWriter, please set:\n'.option(\"mergeSchema\", \"true\")'.\nFor other operations, set the session configuration\nspark.databricks.delta.schema.autoMerge.enabled to \"true\". See the documentation\nspecific to the operation for details.\n\nTable schema:\nroot\n-- addr_state: string (nullable = true)\n-- count: long (nullable = true)\n\n\nData schema:\nroot\n-- addr_state: string (nullable = true)\n-- count: long (nullable = true)\n-- collateral_value: double (nullable = true)\n\n         ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Attempt to append to the table\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mschemaEvolvedDF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdelta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDELTA_LAKE_DIR_ROOT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/readwriter.py:968\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: A schema mismatch detected when writing to the Delta table (Table ID: 50aecee7-98f2-40ec-85ef-68af054ea14e).\nTo enable schema migration using DataFrameWriter or DataStreamWriter, please set:\n'.option(\"mergeSchema\", \"true\")'.\nFor other operations, set the session configuration\nspark.databricks.delta.schema.autoMerge.enabled to \"true\". See the documentation\nspecific to the operation for details.\n\nTable schema:\nroot\n-- addr_state: string (nullable = true)\n-- count: long (nullable = true)\n\n\nData schema:\nroot\n-- addr_state: string (nullable = true)\n-- count: long (nullable = true)\n-- collateral_value: double (nullable = true)\n\n         "
     ]
    }
   ],
   "source": [
    "# Attempt to append to the table\n",
    "schemaEvolvedDF.write.format(\"delta\").mode(\"append\").save(DELTA_LAKE_DIR_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6cc873-426e-43e6-be17-545e667f2e87",
   "metadata": {},
   "source": [
    "### 6. Supply \"mergeSchema\" option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16dcf766-cf76-4210-aa26-519fd91b9207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "schemaEvolvedDF.write.option(\"mergeSchema\",True).format(\"delta\").mode(\"append\").save(DELTA_LAKE_DIR_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a56affe-a463-4835-a45a-51cbdeda8f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|addr_state|count|    collateral_value|\n",
      "+----------+-----+--------------------+\n",
      "|        IA|   94|   948770.9115653402|\n",
      "|        CA| 9939| 9.939137216157739E7|\n",
      "|        IN| 3850|3.8502319893542394E7|\n",
      "|        IA|  555|                null|\n",
      "|        CA|12345|                null|\n",
      "|        IN| 6666|                null|\n",
      "+----------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM loan_db.loans_by_state_delta\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e62673bc-a1d8-41ff-840a-5e608a96f95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://dll-data-bucket-885979867746/delta-consumable/:\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/part-00000-19db8128-746a-4cbd-9a35-ce10d21dbf3a-c000.snappy.parquet\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/part-00000-1ddad42e-603a-40c6-83b7-4ea3ae4a5128-c000.snappy.parquet\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/part-00000-407faca5-0109-4def-a655-a688e694cc6b-c000.snappy.parquet\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/part-00000-9566ead4-572a-4cc0-ba48-605bdfa18778-c000.snappy.parquet\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/part-00000-efb9177f-a191-4835-928a-0d7e4b72e8e0-c000.snappy.parquet\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/part-00000-f028020a-487f-4de7-9fb5-be01dd31b7af-c000.snappy.parquet\n",
      "\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/:\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000000.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000001.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000002.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000003.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000004.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000005.json\n",
      "\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_symlink_format_manifest/:\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_symlink_format_manifest/\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_symlink_format_manifest/manifest\n"
     ]
    }
   ],
   "source": [
    "# Lets look at our datalake and changes from the above execution\n",
    "!gsutil ls -r $DELTA_LAKE_DIR_ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70e7ef-f6e2-4eac-8347-2663afe8dc39",
   "metadata": {},
   "source": [
    "There is one extra parquet, containing the data with thenew column, and one new transaction log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a1c1b4-63ac-42fa-a983-b100c3b4f707",
   "metadata": {},
   "source": [
    "Lets look at the log-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5baabb14-1f11-42f8-ae2c-11793f4800bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommandException: No URLs matched: gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000006.json\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat \"gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000006.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6561e8e8-d991-4cbe-a13a-8b546a821a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/:\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000000.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000001.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000002.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000003.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000004.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000005.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000006.json\n"
     ]
    }
   ],
   "source": [
    "# Lets add data again till we hit the 10th version of the table\n",
    "schemaEvolvedDF = sql(\"select addr_state, cast(rand(10)*count as bigint) as count, cast(rand(10) * 10000 * count as double) as collateral_value from loan_db.loans_by_state_delta\")\n",
    "schemaEvolvedDF.write.format(\"delta\").mode(\"append\").save(DELTA_LAKE_DIR_ROOT)\n",
    "!gsutil ls -r $DELTA_LAKE_DIR_ROOT/_delta_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e07a082-186f-4185-85fb-84bd30ca8c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/:\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000000.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000001.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000002.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000003.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000004.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000005.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000006.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000007.json\n"
     ]
    }
   ],
   "source": [
    "# Lets add data again till we hit the 10th version of the table\n",
    "schemaEvolvedDF = sql(\"select addr_state, cast(rand(10)*count as bigint) as count, cast(rand(10) * 10000 * count as double) as collateral_value from loan_db.loans_by_state_delta\")\n",
    "schemaEvolvedDF.write.format(\"delta\").mode(\"append\").save(DELTA_LAKE_DIR_ROOT)\n",
    "!gsutil ls -r $DELTA_LAKE_DIR_ROOT/_delta_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce35fc2d-f72d-4bf6-abe0-c0f902b7378b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/:\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000000.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000001.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000002.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000003.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000004.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000005.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000006.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000007.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000008.json\n"
     ]
    }
   ],
   "source": [
    "# Lets add data again till we hit the 10th version of the table\n",
    "schemaEvolvedDF = sql(\"select addr_state, cast(rand(10)*count as bigint) as count, cast(rand(10) * 10000 * count as double) as collateral_value from loan_db.loans_by_state_delta\")\n",
    "schemaEvolvedDF.write.format(\"delta\").mode(\"append\").save(DELTA_LAKE_DIR_ROOT)\n",
    "!gsutil ls -r $DELTA_LAKE_DIR_ROOT/_delta_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "444a5169-b3bf-4555-be6f-1cb177e73b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/:\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000000.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000001.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000002.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000003.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000004.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000005.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000006.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000007.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000008.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000009.json\n"
     ]
    }
   ],
   "source": [
    "# Lets add data again till we hit the 10th version of the table\n",
    "schemaEvolvedDF = sql(\"select addr_state, cast(rand(10)*count as bigint) as count, cast(rand(10) * 10000 * count as double) as collateral_value from loan_db.loans_by_state_delta\")\n",
    "schemaEvolvedDF.write.format(\"delta\").mode(\"append\").save(DELTA_LAKE_DIR_ROOT)\n",
    "!gsutil ls -r $DELTA_LAKE_DIR_ROOT/_delta_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bf33ccf-29f6-4f28-8c96-1e339387c7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/:\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000000.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000001.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000002.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000003.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000004.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000005.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000006.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000007.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000008.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000009.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000010.checkpoint.parquet\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/00000000000000000010.json\n",
      "gs://dll-data-bucket-885979867746/delta-consumable/_delta_log/_last_checkpoint\n"
     ]
    }
   ],
   "source": [
    "# Lets add data again till we hit the 10th version of the table\n",
    "schemaEvolvedDF = sql(\"select addr_state, cast(rand(10)*count as bigint) as count, cast(rand(10) * 10000 * count as double) as collateral_value from loan_db.loans_by_state_delta\")\n",
    "schemaEvolvedDF.write.format(\"delta\").mode(\"append\").save(DELTA_LAKE_DIR_ROOT)\n",
    "!gsutil ls -r $DELTA_LAKE_DIR_ROOT/_delta_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824ff198-61b3-469a-997b-d16f1f40a3de",
   "metadata": {},
   "source": [
    "Note how there is a parquet file created - this is a compacted version of table changes 0-9\n",
    "Delta will load this parquet into memory, to avoid having to read too many small files\n",
    "At any given point of time, delta will not read more than 10 json transaction logs, but will read all the parquet transaction logs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676817ca-622f-4d0d-b09b-45e6dae5f2e6",
   "metadata": {},
   "source": [
    "### THIS CONCLUDES THIS UNIT. PROCEED TO THE NEXT NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "serverless_spark": "{\"name\":\"projects/delta-lake-lab/locations/us-central1/sessions/delta-lake-lab-17718\",\"uuid\":\"cb959c82-1002-4915-aed8-85c83d4e81f4\",\"createTime\":\"2022-10-22T17:30:32.565848Z\",\"jupyterSession\":{},\"spark\":{},\"runtimeInfo\":{\"endpoints\":{\"Spark History Server\":\"https://smmei2wdurb7nptroshcbbgeda-dot-us-central1.dataproc.googleusercontent.com/sparkhistory/\"}},\"state\":\"ACTIVE\",\"stateTime\":\"2022-10-22T17:32:38.942362Z\",\"creator\":\"admin@akhanolkar.altostrat.com\",\"runtimeConfig\":{\"version\":\"2.0\",\"properties\":{\"spark:spark.jars.packages\":\"io.delta:delta-core_2.13:2.1.0\",\"spark:spark.sql.catalog.spark_catalog\":\"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\"spark:spark.sql.extensions\":\"io.delta.sql.DeltaSparkSessionExtension\",\"spark:spark.executor.instances\":\"2\",\"spark:spark.driver.cores\":\"4\",\"spark:spark.executor.cores\":\"4\",\"spark:spark.dynamicAllocation.executorAllocationRatio\":\"0.3\",\"spark:spark.eventLog.dir\":\"gs://dll-sphs-bucket-885979867746/cb959c82-1002-4915-aed8-85c83d4e81f4/spark-job-history\"}},\"environmentConfig\":{\"executionConfig\":{\"serviceAccount\":\"dll-lab-sa@delta-lake-lab.iam.gserviceaccount.com\",\"subnetworkUri\":\"spark-snet\",\"idleTtl\":\"14400s\"},\"peripheralsConfig\":{\"metastoreService\":\"projects/delta-lake-lab/locations/us-central1/services/dll-hms-885979867746\",\"sparkHistoryServerConfig\":{\"dataprocCluster\":\"projects/delta-lake-lab/regions/us-central1/clusters/dll-sphs-885979867746\"}}},\"stateHistory\":[{\"state\":\"CREATING\",\"stateStartTime\":\"2022-10-22T17:30:32.565848Z\"}]}",
  "serverless_spark_kernel_name": "remote-19c93264a411c8234417320a-pyspark",
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
