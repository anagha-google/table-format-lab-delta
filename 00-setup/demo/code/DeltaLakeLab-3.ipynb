{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4529a790-8425-4600-841a-4b094b82eaa8",
   "metadata": {},
   "source": [
    "# Delta Lake Lab \n",
    "## Unit 3: Delta Table Utilities\n",
    "\n",
    "This lab is powered by Dataproc Serverless Spark.\n",
    "\n",
    "In the previous units, we covered the below-\n",
    "1. Create a base delta table off of the parquet base table loan_db.loans_by_state_parquet\n",
    "2. Take a peek under the hood of the Delta table\n",
    "3. Review the delta transaction log\n",
    "4. Look at delta table details\n",
    "5. Look at delta table history\n",
    "6. Create a manifest file\n",
    "7. Review entries in the Hive Metastore (Dataproc Metastore Service)\n",
    "\n",
    "In this unit, we will -\n",
    "1. Review Delta table details\n",
    "2. Review Delta table history\n",
    "3. Learn how to create a manifest file\n",
    "4. Review metastore entries\n,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a31c4fd-d465-4f52-8e56-3775bf499abc",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321bce9-178c-4065-8187-0a5728c1a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql.functions import month, date_format\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from delta.tables import *\n",
    "\n",
    "from google.cloud.exceptions import BadRequest\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed295a74-ed1d-4b5d-831a-1b5dcf73c36f",
   "metadata": {},
   "source": [
    "### 2. Create a Spark session powered by Cloud Dataproc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b383d5ab-a0b9-45ab-a232-34d88f2a0065",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Loan Analysis').getOrCreate()\n",
    "spark\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd13e6-f3f5-4f2c-b4fc-d7e2660c6206",
   "metadata": {},
   "source": [
    "### 3. Declare variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596e31b-749a-4702-8879-6f05f9ff0c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id_output = !gcloud config list --format \"value(core.project)\" 2>/dev/null\n",
    "PROJECT_ID = project_id_output[0]\n",
    "print(\"PROJECT_ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471c6743-a058-462b-851a-f34323f36243",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name_output = !gcloud projects describe $PROJECT_ID | grep name | cut -d':' -f2 | xargs\n",
    "PROJECT_NAME = project_name_output[0]\n",
    "print(\"PROJECT_NAME: \", PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61929dc6-a083-433c-8a13-3d39d9c4a4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_number_output = !gcloud projects describe $PROJECT_ID | grep projectNumber | cut -d':' -f2 | xargs\n",
    "PROJECT_NUMBER = project_number_output[0]\n",
    "print(\"PROJECT_NUMBER: \", PROJECT_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b79fd2-5243-41a4-ae87-e7f9dd87cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LAKE_ROOT_PATH= f\"gs://dll-data-bucket-{PROJECT_NUMBER}\"\n",
    "DELTA_LAKE_DIR_ROOT = f\"{DATA_LAKE_ROOT_PATH}/delta-consumable\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed74d358-e90b-46d0-b81c-1e29c25ccac5",
   "metadata": {},
   "source": [
    "### 4. Peek under the hood of our Delta Lake table (loan_db.loans_by_state_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27de098c-817c-486a-9ad8-53be00d8e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls -r $DELTA_LAKE_DIR_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cbc356-ebb9-4908-8193-c859fed0b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cat $DELTA_LAKE_DIR_ROOT/_delta_log/00000000000000000000.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276caa8b-dd60-48ac-b95c-c1302ec883af",
   "metadata": {},
   "source": [
    "### 5. Table Details\n",
    "https://docs.delta.io/latest/delta-utility.html#id6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe4fa8f-7fe8-44bc-a09f-a894852a901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, DELTA_LAKE_DIR_ROOT)\n",
    "detailDF = deltaTable.detail()\n",
    "detailPDF=detailDF.toPandas()\n",
    "detailPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80b94f1-5750-4aed-a0dd-1fa20804ac1a",
   "metadata": {},
   "source": [
    "### 6. Table History\n",
    "\n",
    "https://docs.delta.io/latest/delta-utility.html#id4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b767fc6d-5fb5-4364-ad62-84b9a69dd9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, DELTA_LAKE_DIR_ROOT)\n",
    "fullHistoryPDF = deltaTable.history().toPandas()    # get the full history of the table\n",
    "lastOperationPDF = deltaTable.history(1).toPandas() # get the last operation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdc034e-0bf6-4a5f-861d-20a96245ab5e",
   "metadata": {},
   "source": [
    "#### Last operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cf9014-2e8d-4988-96a3-230ba4581ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastOperationPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c853d124-684f-47c7-920e-d73db1766cce",
   "metadata": {},
   "source": [
    "#### Full History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49cb41-598f-46c5-b21e-9b79343e6b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullHistoryPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073428e0-5141-4c34-82e3-786224d7b878",
   "metadata": {},
   "source": [
    "### 7. Table manifest file\n",
    "https://docs.delta.io/latest/delta-utility.html#id8\n",
    "\n",
    "You can a generate manifest file for a Delta table that can be used by other processing engines (that is, other than Apache Spark) to read the Delta table. For example, to generate a manifest file that can be used by Presto and Athena to read a Delta table, you run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685f24f4-6569-453a-b39b-7ab1aeefad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, DELTA_LAKE_DIR_ROOT)\n",
    "deltaTable.generate(\"symlink_format_manifest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c7b2c6-7ae1-42ca-bf57-cfa7603757cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls -r $DELTA_LAKE_DIR_ROOT | grep \"_symlink_format_manifest/manifest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dfb0d4-342f-4651-a24c-7097fb2b13f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MANIFEST_LIST = !gsutil ls -r $DELTA_LAKE_DIR_ROOT | grep \"_symlink_format_manifest/manifest\"\n",
    "MANIFEST_FILE = MANIFEST_LIST[0]\n",
    "print(MANIFEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678cc704-db99-4941-bfbd-af363a5f4978",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cat $MANIFEST_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a85df4-20f0-4829-be51-b45639b2ad5a",
   "metadata": {},
   "source": [
    "Using this manifest file, you can create an external table in BigQuery on the Delta Table, except it will be point in time to when the manifest was generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e7c633-f34c-4da1-b7cb-250f94b5d3cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### First let's look at the delta table via Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d7f123-8950-485b-bb04-9020e29def8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"show tables from loan_db;\").show(truncate=False)\n",
    "df = deltaTable.toDF()\n",
    "pdf = df.toPandas()\n",
    "pdf = pdf.sort_values(by='addr_state', ascending=True)\n",
    "print(pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c09661-a020-4bbb-bc3b-baef836bb867",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Now let's create a BigLake table using the manifest file created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3e6230-3ff3-4db0-9b6d-cd23a93da400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper to use BigQuery client to run query/job, return job ID or result as DF\n",
    "def bq_query(sql, show_job_id=False):\n",
    "    \"\"\"\n",
    "    Input: SQL query, as a string, to execute in BigQuery\n",
    "    Returns the query results as a pandas DataFrame, or error, if any\n",
    "    \"\"\"\n",
    "\n",
    "    # Try dry run before executing query to catch any errors\n",
    "    try:\n",
    "        job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "\n",
    "        bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    except BadRequest as err:\n",
    "        print(err)\n",
    "        return\n",
    "\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    client_result = bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    job_id = client_result.job_id\n",
    "\n",
    "    # Wait for query/job to finish running, then get & return data frame\n",
    "    df = client_result.result().to_dataframe()\n",
    "\n",
    "    if show_job_id:\n",
    "        print(f\"Finished job_id: {job_id}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6fc2eb-8017-4fc6-9688-4a7414bf5369",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "DATASET = 'delta_dataset'\n",
    "CONNECTION = 'us.biglake-connection'\n",
    "TABLE_NAME = 'bq_delta_table'\n",
    "URI = 'gs://dll-data-bucket-' + PROJECT_NUMBER + '/delta-consumable/_symlink_format_manifest/manifest'\n",
    "BQSQL = 'CREATE EXTERNAL TABLE ' + DATASET + '.' + TABLE_NAME + ' ' + \\\n",
    "        'WITH CONNECTION `' +  CONNECTION + '` ' + \\\n",
    "        'OPTIONS (' + \\\n",
    "        'format=\"PARQUET\", ' + \\\n",
    "        'uris=[\"' + URI + '\"],' + \\\n",
    "        'file_set_spec_type = \\'NEW_LINE_DELIMITED_MANIFEST\\',' + \\\n",
    "        'max_staleness = INTERVAL 1 DAY,' + \\\n",
    "        'metadata_cache_mode = \\'AUTOMATIC\\'' + \\\n",
    "        ');'\n",
    "\n",
    "\n",
    "print(BQSQL)\n",
    "df = bq_query(BQSQL)\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b163a11e-8070-44e1-8c92-0fb6fa7b056f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Now Query the delta table that you created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ca03d-8e31-4e14-b4e9-0fdceca8aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "BQDELTASQL = 'select addr_state,count from '  + DATASET + '.' + TABLE_NAME + ' order by addr_state ASC;'\n",
    "df = bq_query(BQDELTASQL)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da0d8c0-a73e-400a-9e32-306a9f7fc4e6",
   "metadata": {},
   "source": [
    "### 8. Hive Metastore Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cca2f6d-029c-4cf3-ae9d-9c7983e36fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"show tables in loan_db\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e82375-f053-458b-bd5a-c4414b832f29",
   "metadata": {},
   "source": [
    "### THIS CONCLUDES THIS UNIT. PROCEED TO THE NEXT NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "serverless_spark": "{\"name\":\"projects/delta-labv3/locations/us-central1/sessions/delta-lake-lab-10710\",\"uuid\":\"1450f09d-a6dd-43f7-9377-dd1716bfbb75\",\"createTime\":\"2023-10-11T17:20:19.291370Z\",\"jupyterSession\":{},\"runtimeInfo\":{\"endpoints\":{\"Spark History Server\":\"https://edk3fz6s4rbopfko3lqneqdgvq-dot-us-central1.dataproc.googleusercontent.com/sparkhistory/?eventLogDirFilter=1450f09d-a6dd-43f7-9377-dd1716bfbb75\"}},\"state\":\"ACTIVE\",\"stateTime\":\"2023-10-11T17:21:22.341677Z\",\"creator\":\"admin@jayoleary.altostrat.com\",\"runtimeConfig\":{\"version\":\"2.0.42\",\"properties\":{\"spark:spark.jars.packages\":\"io.delta:delta-core_2.13:2.1.0\",\"spark:spark.sql.catalog.spark_catalog\":\"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\"spark:spark.sql.extensions\":\"io.delta.sql.DeltaSparkSessionExtension\",\"spark:spark.executor.instances\":\"2\",\"spark:spark.driver.cores\":\"4\",\"spark:spark.executor.cores\":\"4\",\"spark:spark.dynamicAllocation.executorAllocationRatio\":\"0.3\",\"spark:spark.eventLog.dir\":\"gs://dll-sphs-bucket-633869479008/1450f09d-a6dd-43f7-9377-dd1716bfbb75/spark-job-history\"}},\"environmentConfig\":{\"executionConfig\":{\"serviceAccount\":\"dll-lab-sa@delta-labv3.iam.gserviceaccount.com\",\"subnetworkUri\":\"spark-snet\",\"idleTtl\":\"3600s\",\"ttl\":\"86400s\"},\"peripheralsConfig\":{\"metastoreService\":\"projects/delta-labv3/locations/us-central1/services/dll-hms-633869479008\",\"sparkHistoryServerConfig\":{\"dataprocCluster\":\"projects/delta-labv3/regions/us-central1/clusters/dll-sphs-633869479008\"}}},\"stateHistory\":[{\"state\":\"CREATING\",\"stateStartTime\":\"2023-10-11T17:20:19.291370Z\"}]}",
  "serverless_spark_kernel_name": "remote-b6b812a77d293235569df8c8-pyspark",
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
