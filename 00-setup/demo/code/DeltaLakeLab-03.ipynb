{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4529a790-8425-4600-841a-4b094b82eaa8",
   "metadata": {},
   "source": [
    "# Delta Lake Lab \n",
    "## Unit 3: Delta Table Utilities\n",
    "\n",
    "This lab is powered by Dataproc Serverless Spark.\n",
    "\n",
    "In the previous unit-\n",
    "1. We created a base table in parquet\n",
    "\n",
    "In this unit, we will -\n",
    "1. Create a base delta table off of the parquet base table loan_db.loans_by_state_parquet\n",
    "2. Take a peek under the hood of the Delta table\n",
    "3. Review the delta transaction log\n",
    "4. Look at delta table details\n",
    "5. Look at delta table history\n",
    "6. Create a manifest file for an unpartitioned delta table - we will create a BigLake table with it in notebook 10\n",
    "7. Review entries in the Hive Metastore (Dataproc Metastore Service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a31c4fd-d465-4f52-8e56-3775bf499abc",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1321bce9-178c-4065-8187-0a5728c1a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql.functions import month, date_format\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from delta.tables import *\n",
    "\n",
    "from google.cloud.exceptions import BadRequest\n",
    "from google.cloud import bigquery\n",
    "\n",
    "import sqlparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed295a74-ed1d-4b5d-831a-1b5dcf73c36f",
   "metadata": {},
   "source": [
    "### 2. Create a Spark session powered by Cloud Dataproc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b383d5ab-a0b9-45ab-a232-34d88f2a0065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/02 23:33:22 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://gdpic-srvls-session-7496b9aa-c1b2-4af0-b19a-eed494ea3479-m.us-central1-c.c.delta-lake-diy-lab.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://gdpic-srvls-session-7496b9aa-c1b2-4af0-b19a-eed494ea3479-m:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe1341bbfd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Loan Analysis').getOrCreate()\n",
    "spark\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd13e6-f3f5-4f2c-b4fc-d7e2660c6206",
   "metadata": {},
   "source": [
    "### 3. Declare variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5596e31b-749a-4702-8879-6f05f9ff0c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID:  delta-lake-diy-lab\n"
     ]
    }
   ],
   "source": [
    "project_id_output = !gcloud config list --format \"value(core.project)\" 2>/dev/null\n",
    "PROJECT_ID = project_id_output[0]\n",
    "print(\"PROJECT_ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "471c6743-a058-462b-851a-f34323f36243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_NAME:  delta-lake-diy-lab\n"
     ]
    }
   ],
   "source": [
    "project_name_output = !gcloud projects describe $PROJECT_ID | grep name | cut -d':' -f2 | xargs\n",
    "PROJECT_NAME = project_name_output[0]\n",
    "print(\"PROJECT_NAME: \", PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61929dc6-a083-433c-8a13-3d39d9c4a4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_NUMBER:  11002190840\n"
     ]
    }
   ],
   "source": [
    "project_number_output = !gcloud projects describe $PROJECT_ID | grep projectNumber | cut -d':' -f2 | xargs\n",
    "PROJECT_NUMBER = project_number_output[0]\n",
    "print(\"PROJECT_NUMBER: \", PROJECT_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8b79fd2-5243-41a4-ae87-e7f9dd87cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LAKE_ROOT_PATH= f\"gs://dll-data-bucket-{PROJECT_NUMBER}\"\n",
    "DELTA_LAKE_DIR_ROOT = f\"{DATA_LAKE_ROOT_PATH}/delta-consumable\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed74d358-e90b-46d0-b81c-1e29c25ccac5",
   "metadata": {},
   "source": [
    "### 4. Peek under the hood of our Delta Lake table (loan_db.loans_by_state_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27de098c-817c-486a-9ad8-53be00d8e9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://dll-data-bucket-11002190840/delta-consumable/:\n",
      "gs://dll-data-bucket-11002190840/delta-consumable/part-00000-83d6b120-d178-4ac4-8c8e-f8d590f5f050-c000.snappy.parquet\n",
      "\n",
      "gs://dll-data-bucket-11002190840/delta-consumable/_delta_log/:\n",
      "gs://dll-data-bucket-11002190840/delta-consumable/_delta_log/\n",
      "gs://dll-data-bucket-11002190840/delta-consumable/_delta_log/00000000000000000000.json\n",
      "\n",
      "gs://dll-data-bucket-11002190840/delta-consumable/_symlink_format_manifest/:\n",
      "gs://dll-data-bucket-11002190840/delta-consumable/_symlink_format_manifest/\n",
      "gs://dll-data-bucket-11002190840/delta-consumable/_symlink_format_manifest/manifest\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -r $DELTA_LAKE_DIR_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89cbc356-ebb9-4908-8193-c859fed0b2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"commitInfo\":{\"timestamp\":1701559198463,\"operation\":\"WRITE\",\"operationParameters\":{\"mode\":\"Overwrite\",\"partitionBy\":\"[]\"},\"isolationLevel\":\"Serializable\",\"isBlindAppend\":false,\"operationMetrics\":{\"numFiles\":\"1\",\"numOutputRows\":\"51\",\"numOutputBytes\":\"978\"},\"engineInfo\":\"Apache-Spark/3.4.0 Delta-Lake/2.4.0\",\"txnId\":\"ef45b4d8-1b6b-4e35-8d69-658760b727e5\"}}\n",
      "{\"protocol\":{\"minReaderVersion\":1,\"minWriterVersion\":2}}\n",
      "{\"metaData\":{\"id\":\"347aa570-3d50-4d3a-8aba-02dcf5b8bcee\",\"format\":{\"provider\":\"parquet\",\"options\":{}},\"schemaString\":\"{\\\"type\\\":\\\"struct\\\",\\\"fields\\\":[{\\\"name\\\":\\\"addr_state\\\",\\\"type\\\":\\\"string\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}},{\\\"name\\\":\\\"count\\\",\\\"type\\\":\\\"long\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}}]}\",\"partitionColumns\":[],\"configuration\":{},\"createdTime\":1701559185896}}\n",
      "{\"add\":{\"path\":\"part-00000-83d6b120-d178-4ac4-8c8e-f8d590f5f050-c000.snappy.parquet\",\"partitionValues\":{},\"size\":978,\"modificationTime\":1701559194480,\"dataChange\":true,\"stats\":\"{\\\"numRecords\\\":51,\\\"minValues\\\":{\\\"addr_state\\\":\\\"AK\\\",\\\"count\\\":1},\\\"maxValues\\\":{\\\"addr_state\\\":\\\"WY\\\",\\\"count\\\":1},\\\"nullCount\\\":{\\\"addr_state\\\":0,\\\"count\\\":0}}\"}}\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat $DELTA_LAKE_DIR_ROOT/_delta_log/00000000000000000000.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276caa8b-dd60-48ac-b95c-c1302ec883af",
   "metadata": {},
   "source": [
    "### 5. Table Details\n",
    "https://docs.delta.io/latest/delta-utility.html#id6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbe4fa8f-7fe8-44bc-a09f-a894852a901d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/02 23:33:42 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------------------------+----+-----------+-------------------------------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|format|id                                  |name|description|location                                         |createdAt              |lastModified           |partitionColumns|numFiles|sizeInBytes|properties|minReaderVersion|minWriterVersion|tableFeatures           |\n",
      "+------+------------------------------------+----+-----------+-------------------------------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|delta |347aa570-3d50-4d3a-8aba-02dcf5b8bcee|null|null       |gs://dll-data-bucket-11002190840/delta-consumable|2023-12-02 23:19:45.896|2023-12-02 23:19:58.873|[]              |1       |978        |{}        |1               |2               |[appendOnly, invariants]|\n",
      "+------+------------------------------------+----+-----------+-------------------------------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, DELTA_LAKE_DIR_ROOT)\n",
    "tableDetailsDF = deltaTable.detail()\n",
    "tableDetailsDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80b94f1-5750-4aed-a0dd-1fa20804ac1a",
   "metadata": {},
   "source": [
    "### 6. Table History\n",
    "\n",
    "https://docs.delta.io/latest/delta-utility.html#id4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "973b1884-23a0-4b43-a9e2-6537e5fd1feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, DELTA_LAKE_DIR_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51492c3-d627-46f6-bc68-ad35edbdeb35",
   "metadata": {},
   "source": [
    "#### Full history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b767fc6d-5fb5-4364-ad62-84b9a69dd9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:=============================>                             (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation|operationParameters                   |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                           |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------+------------+-----------------------------------+\n",
      "|0      |2023-12-02 23:19:58.873|null  |null    |WRITE    |{mode -> Overwrite, partitionBy -> []}|null|null    |null     |null       |Serializable  |false        |{numFiles -> 1, numOutputRows -> 51, numOutputBytes -> 978}|null        |Apache-Spark/3.4.0 Delta-Lake/2.4.0|\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fullHistoryDF = deltaTable.history()\n",
    "fullHistoryDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de8e55-7d36-460b-86c1-50e2c6c0a343",
   "metadata": {},
   "source": [
    "#### Last operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87a9bdf8-9333-4c45-a2f3-edacd5fd725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation|operationParameters                   |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                           |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------+------------+-----------------------------------+\n",
      "|0      |2023-12-02 23:19:58.873|null  |null    |WRITE    |{mode -> Overwrite, partitionBy -> []}|null|null    |null     |null       |Serializable  |false        |{numFiles -> 1, numOutputRows -> 51, numOutputBytes -> 978}|null        |Apache-Spark/3.4.0 Delta-Lake/2.4.0|\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lastOperationDF = deltaTable.history(1)\n",
    "lastOperationDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073428e0-5141-4c34-82e3-786224d7b878",
   "metadata": {},
   "source": [
    "### 7. Table manifest file\n",
    "https://docs.delta.io/latest/delta-utility.html#id8\n",
    "\n",
    "You can a generate manifest file for a Delta table that can be used by other processing engines (that is, other than Apache Spark) to read the Delta table. For example, to generate a manifest file that can be used by Presto and Athena to read a Delta table, you run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0c7b2c6-7ae1-42ca-bf57-cfa7603757cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://dll-data-bucket-11002190840/delta-consumable/_symlink_format_manifest/manifest\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -r $DELTA_LAKE_DIR_ROOT | grep \"_symlink_format_manifest/manifest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4dfb0d4-342f-4651-a24c-7097fb2b13f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://dll-data-bucket-11002190840/delta-consumable/_symlink_format_manifest/manifest\n"
     ]
    }
   ],
   "source": [
    "MANIFEST_LIST = !gsutil ls -r $DELTA_LAKE_DIR_ROOT | grep \"_symlink_format_manifest/manifest\"\n",
    "MANIFEST_FILE = MANIFEST_LIST[0]\n",
    "print(MANIFEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "678cc704-db99-4941-bfbd-af363a5f4978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://dll-data-bucket-11002190840/delta-consumable/part-00000-83d6b120-d178-4ac4-8c8e-f8d590f5f050-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat $MANIFEST_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a85df4-20f0-4829-be51-b45639b2ad5a",
   "metadata": {},
   "source": [
    "Using this manifest file, you can create an external table in BigQuery on the Delta Table, except it will be point in time to when the manifest was generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da0d8c0-a73e-400a-9e32-306a9f7fc4e6",
   "metadata": {},
   "source": [
    "### 8. Hive Metastore Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cca2f6d-029c-4cf3-ae9d-9c7983e36fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/spark/conf/ivysettings.xml will be used\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------------+-----------+\n",
      "|namespace|tableName             |isTemporary|\n",
      "+---------+----------------------+-----------+\n",
      "|loan_db  |loans_by_state_delta  |false      |\n",
      "|loan_db  |loans_by_state_parquet|false      |\n",
      "|loan_db  |loans_cleansed_parquet|false      |\n",
      "+---------+----------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables in loan_db\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e82375-f053-458b-bd5a-c4414b832f29",
   "metadata": {},
   "source": [
    "### THIS CONCLUDES THIS UNIT. PROCEED TO THE NEXT NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "serverless_spark": "{\"name\":\"projects/delta-lake-diy-lab/locations/us-central1/sessions/delta-lake-lab-17460\",\"uuid\":\"7496b9aa-c1b2-4af0-b19a-eed494ea3479\",\"createTime\":\"2023-12-02T23:10:14.351363Z\",\"jupyterSession\":{},\"runtimeInfo\":{\"endpoints\":{\"Spark History Server\":\"https://in7kggl6mfcxxdldiezehugb4i-dot-us-central1.dataproc.googleusercontent.com/sparkhistory/\",\"BYOID Spark History Server\":\"https://in7kggl6mfcxxdldiezehugb4i-dot-us-central1.dataproc.byoid.googleusercontent.com/sparkhistory/\"}},\"state\":\"ACTIVE\",\"stateTime\":\"2023-12-02T23:13:27.294546Z\",\"creator\":\"admin@akhanolkar.altostrat.com\",\"runtimeConfig\":{\"version\":\"2.1.27\",\"properties\":{\"spark:spark.jars.packages\":\"io.delta:delta-core_2.13:2.4.0\",\"spark:spark.sql.catalog.spark_catalog\":\"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\"spark:spark.sql.extensions\":\"io.delta.sql.DeltaSparkSessionExtension\",\"spark:spark.executor.instances\":\"2\",\"spark:spark.driver.cores\":\"4\",\"spark:spark.driver.memory\":\"9600m\",\"spark:spark.executor.cores\":\"4\",\"spark:spark.executor.memory\":\"9600m\",\"spark:spark.dynamicAllocation.executorAllocationRatio\":\"0.3\",\"spark:spark.eventLog.dir\":\"gs://dll-sphs-bucket-11002190840/7496b9aa-c1b2-4af0-b19a-eed494ea3479/spark-job-history\"}},\"environmentConfig\":{\"executionConfig\":{\"serviceAccount\":\"dll-lab-sa@delta-lake-diy-lab.iam.gserviceaccount.com\",\"subnetworkUri\":\"spark-snet\",\"idleTtl\":\"3600s\",\"ttl\":\"86400s\"},\"peripheralsConfig\":{\"metastoreService\":\"projects/delta-lake-diy-lab/locations/us-central1/services/dll-hms-11002190840\",\"sparkHistoryServerConfig\":{\"dataprocCluster\":\"projects/delta-lake-diy-lab/regions/us-central1/clusters/dll-sphs-11002190840\"}}},\"stateHistory\":[{\"state\":\"CREATING\",\"stateStartTime\":\"2023-12-02T23:10:14.351363Z\"}]}",
  "serverless_spark_kernel_name": "remote-d973f900c0bcdc8a7fcee568-pyspark",
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
